{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2Seq Neural Machine Translation with Luong Attention\n",
        "\n",
        "This notebook demonstrates training and evaluating a Seq2Seq model using GRUs and **Luong attention** in PyTorch. It compares three attention mechanisms:\n",
        "- Dot Product\n",
        "- General\n",
        "- Concat\n",
        "\n",
        "We use a subset of the **English-French** dataset from [Tatoeba (ManyThings.org)](https://www.manythings.org/anki/).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "6IwYhOuprnUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Imports and Setup"
      ],
      "metadata": {
        "id": "GQPbql7wrzlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "from dataloader_generator import (\n",
        "    normalizeString,\n",
        "    prepareData,\n",
        "    DatasetEngFra,\n",
        "    collate_batch,\n",
        "    PAD_token, SOS_token, EOS_token\n",
        ")\n",
        "from models import EncoderWithLuongAttention, DecoderWithLuongAttention\n",
        "from utils import train_luong_attention, translate_with_attention, plot_attention\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "seed = 13\n",
        "torch.manual_seed(seed)\n"
      ],
      "metadata": {
        "id": "hygdE0JHrvlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Hyperparameters & Dataset"
      ],
      "metadata": {
        "id": "ANoxuMuCr8ZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_epochs = 20\n",
        "hidden_size = 256\n",
        "BATCH_SIZE = 32\n",
        "learning_rate = 1e-3\n",
        "MAX_LENGTH = 10\n",
        "alignment_modes = ['dot_product', 'concat', 'general']\n",
        "\n",
        "# Download if not exists\n",
        "if not os.path.exists('fra.txt'):\n",
        "    os.system('wget -q https://www.manythings.org/anki/fra-eng.zip')\n",
        "    os.system('unzip -oq fra-eng.zip')\n",
        "\n",
        "# Load and preprocess\n",
        "text_pairs = []\n",
        "for line in open('fra.txt', 'r'):\n",
        "    a = line.find('CC-BY')\n",
        "    line = line[:a].strip()\n",
        "    if '\\t' not in line:\n",
        "        continue\n",
        "    eng, fra = line.split('\\t')\n",
        "    text_pairs.append((normalizeString(eng), normalizeString(fra)))\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', text_pairs)\n",
        "dataset = DatasetEngFra(pairs, input_lang, output_lang)\n",
        "train_dl = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n"
      ],
      "metadata": {
        "id": "ZrV_L7dyr-Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Training Loop Across Modes"
      ],
      "metadata": {
        "id": "Ad0i0r9KsCBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for alignment_mode in alignment_modes:\n",
        "    print(f\"\\n{'=' * 40} {alignment_mode.upper()} MODE {'=' * 40}\")\n",
        "\n",
        "    encoder = EncoderWithLuongAttention(input_lang.n_words, hidden_size).to(device)\n",
        "    decoder = DecoderWithLuongAttention(output_lang.n_words, hidden_size, alignment_mode).to(device)\n",
        "\n",
        "    loss_fn = nn.NLLLoss(ignore_index=PAD_token)\n",
        "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loss = train_luong_attention(\n",
        "        encoder, decoder, train_dl, num_epochs,\n",
        "        loss_fn, encoder_optimizer, decoder_optimizer\n",
        "    )\n",
        "    results[alignment_mode] = {\n",
        "        \"encoder\": encoder,\n",
        "        \"decoder\": decoder,\n",
        "        \"train_loss\": train_loss\n",
        "    }\n"
      ],
      "metadata": {
        "id": "IvVw5MEtsID0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Visualize Sample Translations"
      ],
      "metadata": {
        "id": "gSJn7qT-sUsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sample_translations(encoder, decoder, mode_name):\n",
        "    print(f\"\\nSample translations for {mode_name.upper()} mode:\\n\")\n",
        "    for _ in range(5):\n",
        "        eng, fra = random.choice(text_pairs)\n",
        "        pred, _ = translate_with_attention(encoder, decoder, eng, input_lang, output_lang)\n",
        "        print(f\"Input:    {eng}\")\n",
        "        print(f\"Target:   {fra}\")\n",
        "        print(f\"Predicted:{pred}\\n\")\n",
        "\n",
        "for mode, obj in results.items():\n",
        "    show_sample_translations(obj[\"encoder\"], obj[\"decoder\"], mode)\n"
      ],
      "metadata": {
        "id": "EXCkL0MAsXyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Attention Visualization**"
      ],
      "metadata": {
        "id": "Qv1qsz4TszjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = \"Life is often compared to a journey\"\n",
        "correct_translation = \"la vie est souvent comparée à un voyage.\"\n",
        "\n",
        "for mode, obj in results.items():\n",
        "    print(f\"\\n{mode.upper()} MODE Attention Visualization:\")\n",
        "    output_sentence, attention_weights = translate_with_attention(\n",
        "        obj[\"encoder\"], obj[\"decoder\"], sample_input, input_lang, output_lang\n",
        "    )\n",
        "    print(f\"Predicted: {output_sentence}\")\n",
        "    print(f\"Reference: {correct_translation}\")\n",
        "    plot_attention(sample_input, output_sentence, attention_weights)\n"
      ],
      "metadata": {
        "id": "b1ZApyjjs4l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Loss Plot"
      ],
      "metadata": {
        "id": "FWF7H8yVs9wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "for mode, obj in results.items():\n",
        "    plt.plot(obj[\"train_loss\"], label=mode.upper())\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Epochs for Different Attention Modes\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UuVYsMjXtBXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Conclusion\n",
        "\n",
        "In this notebook, we trained a sequence-to-sequence model with **Luong attention mechanisms** on a subset of the English-French dataset.\n",
        "\n",
        "### Key Observations:\n",
        "\n",
        "- All attention modes were able to generate reasonable translations.\n",
        "- The **concat** and **general** modes tended to be more expressive in attending to longer sequences.\n",
        "- **Dot product** is faster but may be less flexible for some sentence structures.\n",
        "\n",
        "### Final Thoughts:\n",
        "\n",
        "Luong attention adds significant context-awareness by dynamically focusing on relevant encoder outputs. It improves translation quality and interpretability via attention heatmaps.\n",
        "\n",
        "---\n",
        "\n",
        "**Next Steps**\n",
        "- Extend to multi-layer GRU or LSTM\n",
        "- Use beam search for decoding\n",
        "- Train on a larger dataset (like WMT14)\n"
      ],
      "metadata": {
        "id": "dqBHd-KatFmd"
      }
    }
  ]
}